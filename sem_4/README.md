ONNX является открытым стандартом для конвертации моделей разных фреймворков в общий формат. С его помощью упрощается переносимость моделей. Модель ONNX представляет собой граф, в котором в качестве вершин представлены вычислительные операторы, а рёбра выступают в качестве определения последовательности передачи данных между вершинами.

Я немного изменил исходный код в файле test_onnx.py, чтобы сделать данное задание:
Была модфифицирована функция benchmark_model, где теперь на вход принимается строковое значение, или ONNX, или torch.
При прохождении данных через dataloader теперь добавлен второй сценарий, сделанные для torch модели, чтобы можно было засечь ее показатели точности и времени выполнения.
Результат работы данного файла:
![alt text](https://github.com/user-attachments/assets/45adc5d9-f5b9-494c-a36a-e886a08a2425)

Мы можем видеть, что показатели точности остались такими же, что говорит об успешной конвертации в формат ONNX. Мы также видим, что ONNX оказалась бысрее torch модели, что делает ее слегка предпочтительнее при отправки данной модели на прод. Особенно это заметно в случае работы на cpu.
